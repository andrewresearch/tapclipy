{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tap Queries Availible as of 02.01.19\n",
    "\n",
    "This is a brief look at the queries that are currently availible and how to use them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First let's just get setup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tapclipy>=0.1.8 in /opt/conda/lib/python3.6/site-packages (0.1.8)\n",
      "http://192.168.99.102:9000/graphql\n"
     ]
    }
   ],
   "source": [
    "!pip install 'tapclipy>=0.1.8'\n",
    "from tapclipy import tap_connect\n",
    "import json\n",
    "\n",
    "# Create TAP Connection\n",
    "tap = tap_connect.Connect('http://192.168.99.102:9000')\n",
    "tap.fetch_schema()\n",
    "print(tap.url())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean\n",
    "\n",
    "Clean is a query that will clean and format the text depending on which parameters you pass.\n",
    "There are 5 current parameters you can pass.\n",
    "\n",
    "- visible = Replaces all white spaces with dots and new lines with line feeds.\n",
    "- minimal = Removes all extra white spaces and extra new lines, leaving only one of each.\n",
    "- simple = Removes all extra white spaces and extra new lines, leaving only one of each. It will also replace hypens and quotes with their ascii safe equivalents.\n",
    "- preserve = This will replace spaces with dots and preserve the length of the text.\n",
    "- ascii = This will replace all non ascii characters eg any char above 127.\n",
    "\n",
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Visible Clean:\n",
      "----------------------------------------\n",
      "Input Text: \n",
      "\n",
      " This will replace spaces with dots and \n",
      " newlines with line feeds\n",
      "\n",
      "\n",
      "Result: \n",
      "\n",
      " This·will·replace·spaces·with·dots·and·¬·newlines·with·line·feeds\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "RAW JSON RESULT\n",
      "----------------------------------------\n",
      "{\n",
      "  \"data\": {\n",
      "    \"clean\": {\n",
      "      \"analytics\": \"This\\u00b7will\\u00b7replace\\u00b7spaces\\u00b7with\\u00b7dots\\u00b7and\\u00b7\\u00ac\\u00b7newlines\\u00b7with\\u00b7line\\u00b7feeds\",\n",
      "      \"querytime\": 97,\n",
      "      \"message\": \"\",\n",
      "      \"timestamp\": \"2019-01-03T00:37:25.011056Z\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Set our query type to clean\n",
    "query = tap.query('clean')\n",
    "\n",
    "# Set our parameter to visible\n",
    "params = '''{ \"cleanType\":\"visible\" }'''\n",
    "\n",
    "# pass in some test data\n",
    "string = \"This will replace spaces with dots and \\n newlines with line feeds\"\n",
    "\n",
    "# query the api\n",
    "strResult = tap.analyse_text(query, string, params)\n",
    "\n",
    "# Print Result\n",
    "print(\"-\" * 40)\n",
    "print(\"Visible Clean:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Input Text: \\n\\n\", string)\n",
    "print(\"\\n\")\n",
    "print(\"Result: \\n\\n\", strResult[\"data\"][\"clean\"][\"analytics\"])\n",
    "print(\"\\n\")\n",
    "print(\"-\" * 40)\n",
    "print(\"RAW JSON RESULT\")\n",
    "print(\"-\" * 40)\n",
    "print(json.dumps(strResult, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotations\n",
    "\n",
    "Annotation is a query that will splitup the text into json data, including seperating the sentences into their own array and providing various stats on each word. \n",
    "\n",
    "The stats provided for each word:\n",
    "\n",
    "- lemma = provides the intended meaning of the word based on it's inflection You can find out more about Lemmatisation [here](https://en.wikipedia.org/wiki/Lemmatisation)\n",
    "- parent = returns the word this word is dependant on\n",
    "- pos tag = returns the part of speech tag for this word, learn more [here](https://nlp.stanford.edu/software/tagger.shtml)\n",
    "- child = returns the word that is dependant on this word\n",
    "- dep type = returns the dependency type, learn more [here](https://nlp.stanford.edu/software/dependencies_manual.pdf)\n",
    "- ner tag = returns the named entity recognized if any. learn more [here](https://nlp.stanford.edu/software/CRF-NER.shtml)\n",
    "\n",
    "This query can provide different outcomes based on the pipeline type passed.\n",
    "\n",
    "possible pipelines:\n",
    "\n",
    "- clu = returns the lemma, pos tag and ner tag\n",
    "- standard = returns the lemma, pos tag, parent, children and dep type\n",
    "- fast = returns the lemma and pos tag\n",
    "- ner = returns the lemma, pos tag, parent, children, dep type and ner tag.\n",
    "\n",
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Annotations:\n",
      "----------------------------------------\n",
      "Input Text:\n",
      "\n",
      " This is the first sentence. This is the second sentence.\n",
      "\n",
      "\n",
      "Raw Result:\n",
      "\n",
      "\n",
      "{\n",
      "  \"data\": {\n",
      "    \"annotations\": {\n",
      "      \"analytics\": [\n",
      "        {\n",
      "          \"idx\": 0,\n",
      "          \"start\": 0,\n",
      "          \"end\": 6,\n",
      "          \"length\": 6,\n",
      "          \"tokens\": [\n",
      "            {\n",
      "              \"idx\": 0,\n",
      "              \"term\": \"This\",\n",
      "              \"lemma\": \"this\",\n",
      "              \"postag\": \"DT\",\n",
      "              \"parent\": 1,\n",
      "              \"children\": [],\n",
      "              \"deptype\": \"nsubj\",\n",
      "              \"nertag\": \"O\"\n",
      "            },\n",
      "            {\n",
      "              \"idx\": 1,\n",
      "              \"term\": \"is\",\n",
      "              \"lemma\": \"be\",\n",
      "              \"postag\": \"VBZ\",\n",
      "              \"parent\": -1,\n",
      "              \"children\": [\n",
      "                0,\n",
      "                4,\n",
      "                5\n",
      "              ],\n",
      "              \"deptype\": \"root\",\n",
      "              \"nertag\": \"O\"\n",
      "            },\n",
      "            {\n",
      "              \"idx\": 2,\n",
      "              \"term\": \"the\",\n",
      "              \"lemma\": \"the\",\n",
      "              \"postag\": \"DT\",\n",
      "              \"parent\": 4,\n",
      "              \"children\": [],\n",
      "              \"deptype\": \"det\",\n",
      "              \"nertag\": \"O\"\n",
      "            },\n",
      "            {\n",
      "              \"idx\": 3,\n",
      "              \"term\": \"first\",\n",
      "              \"lemma\": \"first\",\n",
      "              \"postag\": \"JJ\",\n",
      "              \"parent\": 4,\n",
      "              \"children\": [],\n",
      "              \"deptype\": \"amod\",\n",
      "              \"nertag\": \"O\"\n",
      "            },\n",
      "            {\n",
      "              \"idx\": 4,\n",
      "              \"term\": \"sentence\",\n",
      "              \"lemma\": \"sentence\",\n",
      "              \"postag\": \"NN\",\n",
      "              \"parent\": 1,\n",
      "              \"children\": [\n",
      "                2,\n",
      "                3\n",
      "              ],\n",
      "              \"deptype\": \"attr\",\n",
      "              \"nertag\": \"O\"\n",
      "            },\n",
      "            {\n",
      "              \"idx\": 5,\n",
      "              \"term\": \".\",\n",
      "              \"lemma\": \".\",\n",
      "              \"postag\": \".\",\n",
      "              \"parent\": 1,\n",
      "              \"children\": [],\n",
      "              \"deptype\": \"punct\",\n",
      "              \"nertag\": \"O\"\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"idx\": 1,\n",
      "          \"start\": 6,\n",
      "          \"end\": 12,\n",
      "          \"length\": 6,\n",
      "          \"tokens\": [\n",
      "            {\n",
      "              \"idx\": 0,\n",
      "              \"term\": \"This\",\n",
      "              \"lemma\": \"this\",\n",
      "              \"postag\": \"DT\",\n",
      "              \"parent\": 1,\n",
      "              \"children\": [],\n",
      "              \"deptype\": \"nsubj\",\n",
      "              \"nertag\": \"O\"\n",
      "            },\n",
      "            {\n",
      "              \"idx\": 1,\n",
      "              \"term\": \"is\",\n",
      "              \"lemma\": \"be\",\n",
      "              \"postag\": \"VBZ\",\n",
      "              \"parent\": -1,\n",
      "              \"children\": [\n",
      "                0,\n",
      "                4,\n",
      "                5\n",
      "              ],\n",
      "              \"deptype\": \"root\",\n",
      "              \"nertag\": \"O\"\n",
      "            },\n",
      "            {\n",
      "              \"idx\": 2,\n",
      "              \"term\": \"the\",\n",
      "              \"lemma\": \"the\",\n",
      "              \"postag\": \"DT\",\n",
      "              \"parent\": 4,\n",
      "              \"children\": [],\n",
      "              \"deptype\": \"det\",\n",
      "              \"nertag\": \"O\"\n",
      "            },\n",
      "            {\n",
      "              \"idx\": 3,\n",
      "              \"term\": \"second\",\n",
      "              \"lemma\": \"second\",\n",
      "              \"postag\": \"JJ\",\n",
      "              \"parent\": 4,\n",
      "              \"children\": [],\n",
      "              \"deptype\": \"amod\",\n",
      "              \"nertag\": \"O\"\n",
      "            },\n",
      "            {\n",
      "              \"idx\": 4,\n",
      "              \"term\": \"sentence\",\n",
      "              \"lemma\": \"sentence\",\n",
      "              \"postag\": \"NN\",\n",
      "              \"parent\": 1,\n",
      "              \"children\": [\n",
      "                2,\n",
      "                3\n",
      "              ],\n",
      "              \"deptype\": \"attr\",\n",
      "              \"nertag\": \"O\"\n",
      "            },\n",
      "            {\n",
      "              \"idx\": 5,\n",
      "              \"term\": \".\",\n",
      "              \"lemma\": \".\",\n",
      "              \"postag\": \".\",\n",
      "              \"parent\": 1,\n",
      "              \"children\": [],\n",
      "              \"deptype\": \"punct\",\n",
      "              \"nertag\": \"O\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"querytime\": 33,\n",
      "      \"message\": \"\",\n",
      "      \"timestamp\": \"2019-01-03T01:48:02.378415Z\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Set our query type to annotations\n",
    "query = tap.query('annotations')\n",
    "\n",
    "# Set our pipeline parameter to clu, standard, fast or ner\n",
    "params = '''{ \"pipeType\":\"ner\" }'''\n",
    "\n",
    "# pass in some test data\n",
    "string = \"This is the first sentence. This is the second sentence.\"\n",
    "\n",
    "# query the api\n",
    "strResult = tap.analyse_text(query, string, params)\n",
    "\n",
    "# Print Result\n",
    "print(\"-\" * 40)\n",
    "print(\"Annotations:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Input Text:\\n\\n\", string)\n",
    "print(\"\\n\")\n",
    "print(\"Raw Result:\\n\\n\")\n",
    "print(json.dumps(strResult, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expressions\n",
    "\n",
    "Expressions ia a query that will extract the epistemic expressions of a sentence and list each sentence in it's own array.\n",
    "\n",
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Expressions:\n",
      "----------------------------------------\n",
      "Input Text:\n",
      "\n",
      " This is the first great happy blue angry cold sentence. This is the second fantastic sentence.\n",
      "\n",
      "\n",
      "Raw Result:\n",
      "\n",
      "\n",
      "{\n",
      "  \"data\": {\n",
      "    \"expressions\": {\n",
      "      \"analytics\": [\n",
      "        {\n",
      "          \"sentIdx\": 0,\n",
      "          \"affect\": [\n",
      "            {\n",
      "              \"text\": \"first\"\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"great\"\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"happy\"\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"blue\"\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"angry\"\n",
      "            }\n",
      "          ],\n",
      "          \"epistemic\": [],\n",
      "          \"modal\": []\n",
      "        },\n",
      "        {\n",
      "          \"sentIdx\": 1,\n",
      "          \"affect\": [\n",
      "            {\n",
      "              \"text\": \"fantastic\"\n",
      "            }\n",
      "          ],\n",
      "          \"epistemic\": [],\n",
      "          \"modal\": []\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Set our query type to expressions\n",
    "query = tap.query('expressions')\n",
    "\n",
    "# no params needed\n",
    "\n",
    "# pass in some test data\n",
    "string = \"This is the first great happy blue angry cold sentence. This is the second fantastic sentence.\"\n",
    "\n",
    "# query the api\n",
    "strResult = tap.analyse_text(query, string)\n",
    "\n",
    "# Print Result\n",
    "print(\"-\" * 40)\n",
    "print(\"Expressions:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Input Text:\\n\\n\", string)\n",
    "print(\"\\n\")\n",
    "print(\"Raw Result:\\n\\n\")\n",
    "print(json.dumps(strResult, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syllables\n",
    "\n",
    "Syllables is a query that will return the syllable count for each word in a sentence and group each sentence into it's own array.\n",
    "\n",
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Syllables:\n",
      "----------------------------------------\n",
      "Input Text:\n",
      "\n",
      " This is the first great happy blue angry cold sentence. This is the second fantastic sentence.\n",
      "\n",
      "\n",
      "Raw Result:\n",
      "\n",
      "\n",
      "{\n",
      "  \"data\": {\n",
      "    \"syllables\": {\n",
      "      \"analytics\": [\n",
      "        {\n",
      "          \"sentIdx\": 0,\n",
      "          \"avgSyllables\": 1.1818181818181819,\n",
      "          \"counts\": [\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "            2,\n",
      "            1,\n",
      "            2,\n",
      "            1,\n",
      "            2\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"sentIdx\": 1,\n",
      "          \"avgSyllables\": 1.4285714285714286,\n",
      "          \"counts\": [\n",
      "            1,\n",
      "            1,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "            2\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"timestamp\": \"2019-01-03T01:47:47.632905Z\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Set our query type to syllables\n",
    "query = tap.query('syllables')\n",
    "\n",
    "# no params needed\n",
    "\n",
    "# pass in some test data\n",
    "string = \"This is the first great happy blue angry cold sentence. This is the second fantastic sentence.\"\n",
    "\n",
    "# query the api\n",
    "strResult = tap.analyse_text(query, string)\n",
    "\n",
    "# Print Result\n",
    "print(\"-\" * 40)\n",
    "print(\"Syllables:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Input Text:\\n\\n\", string)\n",
    "print(\"\\n\")\n",
    "print(\"Raw Result:\\n\\n\")\n",
    "print(json.dumps(strResult, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling\n",
    "\n",
    "Spelling is a query that will return the spelling mistakes and possible suggestions for what the intended word was.\n",
    "\n",
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Spelling:\n",
      "----------------------------------------\n",
      "Input Text:\n",
      "\n",
      " Th is the frst graet hpapy blue anrgy cold sentence. This is the second fantastic sentence.\n",
      "\n",
      "\n",
      "Raw Result:\n",
      "\n",
      "\n",
      "{\n",
      "  \"data\": {\n",
      "    \"spelling\": {\n",
      "      \"timestamp\": \"2019-01-03T01:56:44.311809Z\",\n",
      "      \"message\": \"\",\n",
      "      \"querytime\": 13,\n",
      "      \"analytics\": [\n",
      "        {\n",
      "          \"sentIdx\": 0,\n",
      "          \"spelling\": []\n",
      "        },\n",
      "        {\n",
      "          \"sentIdx\": 1,\n",
      "          \"spelling\": []\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Set our query type to Spelling\n",
    "query = tap.query('spelling')\n",
    "\n",
    "# no params needed\n",
    "\n",
    "# pass in some test data\n",
    "string = \"Th is the frst graet hpapy blue anrgy cold sentence. This is the second fantastic sentence.\"\n",
    "\n",
    "# query the api\n",
    "strResult = tap.analyse_text(query, string)\n",
    "\n",
    "# Print Result\n",
    "print(\"-\" * 40)\n",
    "print(\"Spelling:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Input Text:\\n\\n\", string)\n",
    "print(\"\\n\")\n",
    "print(\"Raw Result:\\n\\n\")\n",
    "print(json.dumps(strResult, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary\n",
    "\n",
    "Vocabulary is a query that returns the stats on the vocabulary used, It groups them by unique words and how many times they were used.\n",
    "\n",
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Vocabulary:\n",
      "----------------------------------------\n",
      "Input Text:\n",
      "\n",
      " This is the first great happy blue angry cold sentence. This is the second fantastic sentence.\n",
      "\n",
      "\n",
      "Raw Result:\n",
      "\n",
      "\n",
      "{\n",
      "  \"data\": {\n",
      "    \"vocabulary\": {\n",
      "      \"analytics\": {\n",
      "        \"unique\": 13,\n",
      "        \"terms\": [\n",
      "          {\n",
      "            \"term\": \"this\",\n",
      "            \"count\": 2\n",
      "          },\n",
      "          {\n",
      "            \"term\": \"is\",\n",
      "            \"count\": 2\n",
      "          },\n",
      "          {\n",
      "            \"term\": \".\",\n",
      "            \"count\": 2\n",
      "          },\n",
      "          {\n",
      "            \"term\": \"fantastic\",\n",
      "            \"count\": 1\n",
      "          },\n",
      "          {\n",
      "            \"term\": \"blue\",\n",
      "            \"count\": 1\n",
      "          },\n",
      "          {\n",
      "            \"term\": \"angry\",\n",
      "            \"count\": 1\n",
      "          },\n",
      "          {\n",
      "            \"term\": \"second\",\n",
      "            \"count\": 1\n",
      "          },\n",
      "          {\n",
      "            \"term\": \"cold\",\n",
      "            \"count\": 1\n",
      "          },\n",
      "          {\n",
      "            \"term\": \"happy\",\n",
      "            \"count\": 1\n",
      "          },\n",
      "          {\n",
      "            \"term\": \"first\",\n",
      "            \"count\": 1\n",
      "          },\n",
      "          {\n",
      "            \"term\": \"great\",\n",
      "            \"count\": 1\n",
      "          },\n",
      "          {\n",
      "            \"term\": \"sentence\",\n",
      "            \"count\": 2\n",
      "          },\n",
      "          {\n",
      "            \"term\": \"the\",\n",
      "            \"count\": 2\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"timestamp\": \"2019-01-03T02:31:08.931810Z\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Set our query type to Vocabulary\n",
    "query = tap.query('vocabulary')\n",
    "\n",
    "# no params needed\n",
    "\n",
    "# pass in some test data\n",
    "string = \"This is the first great happy blue angry cold sentence. This is the second fantastic sentence.\"\n",
    "\n",
    "# query the api\n",
    "strResult = tap.analyse_text(query, string)\n",
    "\n",
    "# Print Result\n",
    "print(\"-\" * 40)\n",
    "print(\"Vocabulary:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Input Text:\\n\\n\", string)\n",
    "print(\"\\n\")\n",
    "print(\"Raw Result:\\n\\n\")\n",
    "print(json.dumps(strResult, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "Metrics is a query that will return various stats on the text that was parsed.\n",
    "Metrics such as:\n",
    "\n",
    "- word count\n",
    "- sentence count\n",
    "- average word counts\n",
    "- array of sentences and word counts per sentence\n",
    "\n",
    "\n",
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Vocabulary:\n",
      "----------------------------------------\n",
      "Input Text:\n",
      "\n",
      " This is the first great happy blue angry cold sentence. This is the second fantastic sentence.\n",
      "\n",
      "\n",
      "Raw Result:\n",
      "\n",
      "\n",
      "{\n",
      "  \"data\": {\n",
      "    \"metrics\": {\n",
      "      \"analytics\": {\n",
      "        \"words\": 16,\n",
      "        \"sentences\": 2,\n",
      "        \"sentWordCounts\": [\n",
      "          10,\n",
      "          6\n",
      "        ],\n",
      "        \"averageSentWordCount\": 8\n",
      "      },\n",
      "      \"querytime\": 13,\n",
      "      \"message\": \"\",\n",
      "      \"timestamp\": \"2019-01-03T02:33:33.229210Z\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Set our query type to Metrics\n",
    "query = tap.query('metrics')\n",
    "\n",
    "# no params needed\n",
    "\n",
    "# pass in some test data\n",
    "string = \"This is the first great happy blue angry cold sentence. This is the second fantastic sentence.\"\n",
    "\n",
    "# query the api\n",
    "strResult = tap.analyse_text(query, string)\n",
    "\n",
    "# Print Result\n",
    "print(\"-\" * 40)\n",
    "print(\"Metrics:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Input Text:\\n\\n\", string)\n",
    "print(\"\\n\")\n",
    "print(\"Raw Result:\\n\\n\")\n",
    "print(json.dumps(strResult, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pos Stats (Part Of Speech)\n",
    "\n",
    "Part of speech stats is a query that will return the verb, noun and adjective distribution ratios of the sentences.\n",
    "\n",
    "\n",
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Pos Stats:\n",
      "----------------------------------------\n",
      "Input Text:\n",
      "\n",
      " This is the first great happy blue angry cold sentence. This is the second fantastic sentence.\n",
      "\n",
      "\n",
      "Raw Result:\n",
      "\n",
      "\n",
      "{\n",
      "  \"data\": {\n",
      "    \"posStats\": {\n",
      "      \"analytics\": {\n",
      "        \"verbNounRatio\": 1,\n",
      "        \"futurePastRatio\": 0,\n",
      "        \"adjectiveWordRatio\": 0.5,\n",
      "        \"namedEntityWordRatio\": 1.125,\n",
      "        \"nounDistribution\": [\n",
      "          0.5,\n",
      "          0.5\n",
      "        ],\n",
      "        \"verbDistribution\": [\n",
      "          0.5,\n",
      "          0.5\n",
      "        ],\n",
      "        \"adjectiveDistribution\": [\n",
      "          0.75,\n",
      "          0.25\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Set our query type to posStats\n",
    "query = tap.query('posStats')\n",
    "\n",
    "# no params needed\n",
    "\n",
    "# pass in some test data\n",
    "string = \"This is the first great happy blue angry cold sentence. This is the second fantastic sentence.\"\n",
    "\n",
    "# query the api\n",
    "strResult = tap.analyse_text(query, string)\n",
    "\n",
    "# Print Result\n",
    "print(\"-\" * 40)\n",
    "print(\"Pos Stats:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Input Text:\\n\\n\", string)\n",
    "print(\"\\n\")\n",
    "print(\"Raw Result:\\n\\n\")\n",
    "print(json.dumps(strResult, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflect Expressions\n",
    "\n",
    "Reflect Expressions is a query that will return various stats about the text such as:\n",
    "\n",
    "- word counts\n",
    "- average word length\n",
    "- sentence counts\n",
    "- average sentence lengths\n",
    "- meta tags used such as knowledge, experience or regulation\n",
    "- phrase tags used such as outcome, temporal, pertains, consider, anticipate ..etc\n",
    "\n",
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Reflect Expressions:\n",
      "----------------------------------------\n",
      "Input Text:\n",
      "\n",
      " This is the first great happy blue angry cold sentence I know. This is the second fantastic sentence.\n",
      "\n",
      "\n",
      "Raw Result:\n",
      "\n",
      "\n",
      "{\n",
      "  \"data\": {\n",
      "    \"reflectExpressions\": {\n",
      "      \"querytime\": 11,\n",
      "      \"analytics\": {\n",
      "        \"counts\": {\n",
      "          \"wordCount\": 18,\n",
      "          \"avgWordLength\": 4.555555555555555,\n",
      "          \"sentenceCount\": 2,\n",
      "          \"avgSentenceLength\": 9\n",
      "        },\n",
      "        \"summary\": {\n",
      "          \"metaTagSummary\": {\n",
      "            \"knowledge\": 0,\n",
      "            \"experience\": 0,\n",
      "            \"regulation\": 0,\n",
      "            \"none\": 2\n",
      "          },\n",
      "          \"phraseTagSummary\": {\n",
      "            \"outcome\": 0,\n",
      "            \"temporal\": 0,\n",
      "            \"pertains\": 0,\n",
      "            \"consider\": 1,\n",
      "            \"anticipate\": 0,\n",
      "            \"definite\": 0,\n",
      "            \"possible\": 0,\n",
      "            \"selfReflexive\": 0,\n",
      "            \"emotive\": 0,\n",
      "            \"selfPossessive\": 0,\n",
      "            \"compare\": 0,\n",
      "            \"manner\": 0,\n",
      "            \"none\": 1\n",
      "          }\n",
      "        },\n",
      "        \"tags\": [\n",
      "          {\n",
      "            \"sentence\": \"this be the first great happy blue angry cold sentence i know .\",\n",
      "            \"phrases\": [\n",
      "              \"i know[consider,10,11]\",\n",
      "              \"i know[generalPronounVerb,10,11]\"\n",
      "            ],\n",
      "            \"subTags\": [],\n",
      "            \"metaTags\": []\n",
      "          },\n",
      "          {\n",
      "            \"sentence\": \"this be the second fantastic sentence .\",\n",
      "            \"phrases\": [],\n",
      "            \"subTags\": [],\n",
      "            \"metaTags\": []\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Set our query type to reflectExpressions\n",
    "query = tap.query('reflectExpressions')\n",
    "\n",
    "# no params needed\n",
    "\n",
    "# pass in some test data\n",
    "string = \"This is the first great happy blue angry cold sentence I know. This is the second fantastic sentence.\"\n",
    "\n",
    "# query the api\n",
    "strResult = tap.analyse_text(query, string)\n",
    "\n",
    "# Print Result\n",
    "print(\"-\" * 40)\n",
    "print(\"Reflect Expressions:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Input Text:\\n\\n\", string)\n",
    "print(\"\\n\")\n",
    "print(\"Raw Result:\\n\\n\")\n",
    "print(json.dumps(strResult, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affect Expressions\n",
    "\n",
    "Affect Expressions is a query that will return stats about the valence, arousal and dominance language used.\n",
    "\n",
    "You are able to pass in the thresholds at which each of them will trigger.\n",
    "\n",
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Affect Expressions:\n",
      "----------------------------------------\n",
      "Input Text:\n",
      "\n",
      " This is the first great happy blue angry cold sentence I know. This is the second fantastic sentence.\n",
      "\n",
      "\n",
      "Raw Result:\n",
      "\n",
      "\n",
      "{\n",
      "  \"data\": {\n",
      "    \"affectExpressions\": {\n",
      "      \"querytime\": 84,\n",
      "      \"message\": \"\",\n",
      "      \"timestamp\": \"2019-01-03T03:01:27.529517Z\",\n",
      "      \"analytics\": [\n",
      "        {\n",
      "          \"affect\": [\n",
      "            {\n",
      "              \"text\": \"first\",\n",
      "              \"valence\": 7.33,\n",
      "              \"arousal\": 4.9,\n",
      "              \"dominance\": 6.38,\n",
      "              \"startIdx\": 3\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"great\",\n",
      "              \"valence\": 7.5,\n",
      "              \"arousal\": 4.14,\n",
      "              \"dominance\": 6.65,\n",
      "              \"startIdx\": 4\n",
      "            },\n",
      "            {\n",
      "              \"text\": \"happy\",\n",
      "              \"valence\": 8.47,\n",
      "              \"arousal\": 6.05,\n",
      "              \"dominance\": 7.21,\n",
      "              \"startIdx\": 5\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"affect\": [\n",
      "            {\n",
      "              \"text\": \"fantastic\",\n",
      "              \"valence\": 8.36,\n",
      "              \"arousal\": 6.4,\n",
      "              \"dominance\": 7.21,\n",
      "              \"startIdx\": 4\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Set our query type to affectExpressions\n",
    "query = tap.query('affectExpressions')\n",
    "\n",
    "# Set our thresholds in a parameter\n",
    "params = '''\n",
    "{\n",
    "    \"valence\":4,\n",
    "    \"arousal\":4,\n",
    "    \"dominance\":4\n",
    "}\n",
    "'''\n",
    "\n",
    "# pass in some test data\n",
    "string = \"This is the first great happy blue angry cold sentence I know. This is the second fantastic sentence.\"\n",
    "\n",
    "# query the api\n",
    "strResult = tap.analyse_text(query, string, params)\n",
    "\n",
    "# Print Result\n",
    "print(\"-\" * 40)\n",
    "print(\"Affect Expressions:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Input Text:\\n\\n\", string)\n",
    "print(\"\\n\")\n",
    "print(\"Raw Result:\\n\\n\")\n",
    "print(json.dumps(strResult, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
